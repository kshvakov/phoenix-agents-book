---
title: "Глава 9: Команда агентов + управление"
description: "Как масштабировать практику: multi-agent подход, роли и артефакты, governance, quality gates и принятие решений на доказательствах."
lastmod: 2026-01-21
weight: 9
---

# Глава 9: Команда агентов + управление

## Пролог: Parts Unlimited. Payroll‑инцидент и «команда в коробке»

**Ночь, пятница.** Payroll‑система недоступна — а значит, часть сотрудников может не получить зарплату вовремя. Дежурный инженер поднимает инцидент P0.

### 2014: координация руками

Bill Palmer созывает людей в конференц‑колл.

- **Wes Davis** — смотрит приложение и деплой
- **Patty McKee** — смотрит инфраструктуру
- **Brent** — лезет в легаси‑БД

Через какое‑то время выясняется: упала миграция БД, сервис читает схему, которой в проде ещё нет. Инцидент решают, но неизбежно проявляются старые проблемы:

1. **Сбор команды занимает время** (людей надо разбудить, подключить, ввести в контекст).
2. **Дублирование работы** (каждый «на всякий случай» смотрит одни и те же логи).
3. **Склейка контекста вручную** (кто‑то должен свести таймлайн, гипотезы, факты, решения).
4. **Знание не фиксируется** как переиспользуемый процесс: следующий раз начинается заново.

### 2026: «команда в коробке»

К 2026 Parts Unlimited уже использует агентов (главы 5–8), но для сложных инцидентов важны **параллельность, специализация и управляемое принятие решений**. Поэтому появляется следующая ступень: **multi-agent система для реагирования на инциденты**.

Она не «чинит магией» и не обещает идеальной точности. Она делает другое: **собирает доказательства и формирует решение‑пакет быстрее и ровнее**, чем это получается у людей в ночном созвоне.

Когда падает payroll, инженер видит не просто чат‑бота, а рабочий процесс:

- Система создаёт **единый контекст инцидента** (тикет/канал/таймлайн/артефакты).
- Оркестратор запускает **несколько специализированных агентов** (аналитика, триаж, SRE‑диагностика, ревью риска).
- На выходе появляется **decision packet** — краткий, проверяемый документ: что произошло, какие факты, что предлагается сделать, какие риски, что требует подтверждения человека.

---

## Что такое multi-agent система (в контексте этой книги)

В этой книге **multi-agent система** — это **организованная работа нескольких специализированных LLM‑агентов**, которые решают одну задачу, обмениваясь структурированными артефактами, а их работу **координирует оркестратор**, применяющий политики безопасности и качества.

Важно: multi-agent система — это **не модель** и не «много промптов». Это **система** из компонентов и ограничений.

### Компоненты системы

- **Orchestrator**: режет задачу на подзадачи, назначает исполнителей, собирает результаты, фиксирует решения, эскалирует человеку.
- **Specialized agents**: каждый отвечает за свой кусок работы и отдаёт артефакт понятного формата (Analyst, Triage, SRE, Reviewer).
- **Tool adapters**: как агенты получают факты и выполняют действия (observability, SSH/CLI, CM/Ansible, тикеты) — без «доступа ко всему миру».
- **Context store**: единое место, где живут таймлайн, гипотезы, вывод команд, ссылки на графики, принятые решения.
- **Policy/permissions layer**: что агентам разрешено (read‑only по умолчанию, allowlist команд, лимиты на действия, обязательные точки human‑in‑the‑loop).
- **Audit log**: кто что сделал/предложил/утвердил и почему — пригодно для постмортема и контроля.

### Границы и реализм: что система НЕ обещает

- **Не обещает «0 секунд» и «нулевых потерь контекста»**: она сокращает ручную склейку и ускоряет старт, но задержки, шум и ошибки остаются.
- **Не имеет “супер‑доступа”**: действует только в рамках выданных прав и технических ограничений.
- **Не подменяет ответственность**: рискованные изменения требуют подтверждения человека; Reviewer имеет право остановки.
- **Не гарантирует корректность**: модели ошибаются, поэтому нужны контракты, проверки, политики и аудит.

### Схема: как выглядит поток работ

```text
IncidentIntake
    |
    v
Orchestrator  ----------------------->  ContextStore
    |                      ^              ^
    |                      |              |
    +--> AnalystAgent -----+--------------+
    +--> TriageAgent ------+--------------+
    +--> SREAgent ---------+--------------+
    +--> ReviewerAgent ----+--------------+
    |
    v
DecisionPacket  --->  [HumanApproval (optional)]  --->  ExecuteChange  --->  AuditLog
     \                                                           \
      \                                                           v
       +------------------------------->  PostmortemInputs  <------+
```

---

## Decision packet: минимальный «контракт» между системой и человеком

Вместо простыни логов или длинного диалога, multi-agent система должна уметь сформировать краткий и проверяемый пакет решения:

```json
{
  "incident": {"id": "INC-...", "severity": "P0", "symptoms": ["payroll down"]},
  "timeline": [{"time": "02:10", "event": "deploy payroll-service v1.2.3"}],
  "top_hypotheses": [{"id": "H2", "summary": "failed DB migration", "confidence": "MEDIUM"}],
  "evidence": [{"source": "logs", "snippet": "ERROR: column ... does not exist"}],
  "proposed_actions": [
    {"type": "diagnostic", "description": "verify schema_migrations status", "safe": true},
    {"type": "change", "description": "rollback payroll-service to v1.2.2", "requires_approval": true}
  ],
  "risk": {"blast_radius": "payroll-service", "data_risk": "unknown"},
  "review": {"status": "STOP", "reason": "no staging verification"},
  "next_step": "escalate_to_human"
}
```

Этот формат важен не сам по себе, а как дисциплина: **система обязана отделять факты от гипотез и явно отмечать точки риска**.

Практическое правило: `decision packet` должен быть **валидируемым артефактом** (например, по JSON‑схеме) и входить в eval‑контур из главы 8. Минимум: для каждой предлагаемой первопричины должны быть явные `evidence[]` (что можно проверить). Если доказательств нет — статус “UNCONFIRMED” и обязательная эскалация.

---

## Быстрый старт (прототип за 1–2 часа, продакшен — за дни/недели)

Если вы хотите «пощупать» multi-agent подход на одном типовом инциденте:

1. **Определите роли и артефакты**: что выдаёт Analyst (таймлайн), Triage (гипотезы), SRE (факты/диагностика), Reviewer (решение/стоп‑флаг).
2. **Опишите политики**: read‑only по умолчанию, allowlist команд, обязательная эскалация при `STOP` или неопределённости.
3. **Соберите “context store”**: хотя бы один документ/тикет, куда складываются ссылки на графики, вывод команд и решения.
4. **Сделайте маленький eval‑набор** из 10–20 прошлых инцидентов: на нём вы быстро увидите, где агент «галлюцинирует» и где ломаются контракты.

Дальше в главе мы разберём, как устроить роли, оркестрацию и governance так, чтобы система оставалась управляемой и безопасной.


## Теория: команда агентов, оркестрация, governance

### Концепция 1: Специализация агентов — каждый делает одну вещь хорошо

**Проблема с 1 универсальным агентом:**

Агент (главы 5–8) может делать всё: триаж, исправления, ревью. Но:
- Сложные задачи требуют глубокой экспертизы (миграции БД, диагностика сети, проверка безопасности)
- 1 агент не может быть экспертом во всём
- Универсальный агент = "мастер на все руки, но специалист ни в чём"

**Решение: специализированные агенты**

## Команда из 4 специализированных агентов

### Агент‑аналитик

**Роль:** аналитик данных — строит хронологию и выявляет паттерны.

**Ответственность:**
- Парсит логи/метрики из нескольких источников
- Строит хронологию (что произошло и когда)
- Выявляет аномалии (что изменилось нетипично)
- Коррелирует события (деплой → сработал алерт → запросы начали падать)

**Вход:** логи, метрики, алерты за период N
**Выход:** хронология + затронутые сервисы + недавние изменения

**Специализация:** знает как парсить логи разных форматов, умеет строить графы зависимостей.

---

### Triage Agent

**Роль:** диагност — генерирует и ранжирует гипотезы.

**Ответственность:**
- На основе хронологии строит гипотезы (возможные первопричины)
- Ранжирует по вероятности
- Для каждой гипотезы: обоснование (почему эта гипотеза вероятна)

**Вход:** хронология от агента‑аналитика
**Выход:** ранжированные гипотезы с обоснованием

**Специализация:** знает паттерны типичных инцидентов (деплой → падение приложения, миграция → ошибки БД, изменение конфигурации → проблема сети).

---

### SRE Agent

**Роль:** SRE — выполняет диагностические команды и предлагает исправления.

**Ответственность:**
- Для каждой гипотезы генерирует диагностические команды
- Выполняет команды автономно (если это поддержано инструментами и выданными правами: read‑only по умолчанию, allowlist команд, human‑in‑the‑loop для рискованных действий)
- Интерпретирует вывод (подтверждает или отвергает гипотезу)
- Предлагает исправление если первопричина подтверждена

**Вход:** гипотезы от агента триажа
**Выход:** результаты диагностики + предлагаемое исправление

**Специализация:** знает Linux/systemd, deb‑релизы через Ansible, операции с БД, сетевые утилиты; умеет выполнять команды безопасно.

---

### Reviewer Agent

**Роль:** ревьюер безопасности — проверяет, что исправление безопасно.

**Ответственность:**
- Проверяет предлагаемое исправление на безопасность (не повредит данные продакшена)
- Проверяет радиус поражения: какие сервисы затронуты
- Проверяет обратимость: можем ли откатить исправление
- Рекомендует staging-тест, если исправление рискованное

**Вход:** предлагаемое исправление от SRE‑агента
**Выход:** Одобрено / STOP + обоснование

**Специализация:** знает режимы отказа, знает политики компании: staging-тест обязателен для критичных изменений.

---

## Принцип специализации

**Каждый агент:**
- Делает 1 вещь (сфокусированная роль)
- Делает её хорошо (глубокая экспертиза)
- Не дублирует работу других (чёткие границы ответственности)

**Оркестратор:**
- Координирует агентов (кто когда что делает)
- Собирает результаты (склеивает вывод от каждого агента)
- Принимает решения (эскалировать или продолжать)

В 2014 Bill был «универсальным координатором» — делал всё сам или делегировал хаотично. В 2026 каждый агент специализирован → качество выше.

### Концепция 2: оркестрация — кто координирует команду

**Проблема без оркестратора:**

4 специализированных агента, но нет координатора:
- Кто решает, когда запускать агента‑аналитика? Когда агента триажа?
- Кто собирает результаты от каждого агента?
- Кто принимает решение: эскалировать или применить исправление?

**Решение: агент‑оркестратор**

## Агент‑оркестратор

**Роль:** координатор команды — управляет воркфлоу.

**Ответственность:**

1. **Маршрутизация:** определяет, какой агент нужен для задачи
   - Сработал инцидент → запусти агента‑аналитика (построить хронологию)
   - Хронология готова → запусти агента триажа (сгенерировать гипотезы)
   - Гипотезы готовы → запусти SRE‑агента (диагностика)

2. **Параллельное выполнение:** запускает агентов параллельно, где возможно
   - Агент‑аналитик + агент триажа могут работать одновременно (если хронология уже известна)
   - Нельзя: SRE‑агент не может начать до того, как агент триажа сгенерировал гипотезы

3. **Передача контекста:** передаёт результат одного агента как вход другому
   - Вывод аналитика → вход триажа
   - Вывод триажа → вход SRE
   - Вывод SRE → вход ревьюера

4. **Принятие решений:** принимает решения на основе результатов
   - Ревьюер говорит "STOP" → эскалировать к человеку
   - Ревьюер говорит "Approved" → применить исправление
   - Все гипотезы проверены, первопричина не найдена → эскалировать

5. **Эскалация:** зовёт человека, если есть неопределённость
   - Противоречивые результаты: triage ставит HIGH, SRE не находит доказательств
   - Рискованное исправление: Reviewer говорит "STOP, сначала тест на staging"
   - Неизвестный сценарий: нет подходящей гипотезы

**Движок воркфлоу:**

```python
# Псевдокод оркестратора

def handle_incident(incident):
    # Этап 1: собрать информацию
    timeline = analyst.build_timeline(incident)
    
    # Этап 2: сгенерировать гипотезы
    hypotheses = triage.generate_hypotheses(timeline)
    
    # Этап 3: диагностика (параллельно для каждой гипотезы)
    diagnostics = []
    for hypothesis in hypotheses:
        result = sre.run_diagnostics(hypothesis)
        diagnostics.append(result)
    
    # Этап 4: определить первопричину
    root_cause = find_confirmed_hypothesis(diagnostics)
    
    if not root_cause:
        return escalate("первопричина не найдена", diagnostics)
    
    # Этап 5: предложить исправление
    proposed_fix = sre.generate_fix(root_cause)
    
    # Этап 6: ревью исправления
    review = reviewer.review_fix(proposed_fix)
    
    if review.status == "STOP":
        return escalate(review.reason, proposed_fix)
    
    # Этап 7: применить исправление
    return apply_fix(proposed_fix)
```

**Ключевое:** оркестратор не делает диагностику сам — он управляет воркфлоу: кто когда что делает.

В 2014 Bill был «оркестратором» (вручную координировал). В 2026 агент‑оркестратор автоматизирует координацию.

### Концепция 3: протокол коммуникации — как агенты общаются

**Проблема:**

Агенты должны передавать данные друг другу:
- Analyst → Triage: хронология
- Triage → SRE: гипотезы
- SRE → Reviewer: предлагаемое исправление

**Как структурировать коммуникацию?**

**Решение: структурированные сообщения**

**Протокол коммуникации**

**Формат сообщений**

Все агенты используют единый формат:

```json
{
  "from": "analyst_agent",
  "to": "triage_agent",
  "message_type": "timeline",
  "timestamp": "2026-01-17T02:00:45Z",
  "data": {
    "timeline": [...],
    "affected_services": [...],
    "recent_changes": [...]
  }
}
```

### Типы сообщений

**1. Хронология:**
```json
{
  "message_type": "timeline",
  "data": {
    "timeline": [
      {"time": "<TIME>", "event": "деплой v1.2.3"},
      {"time": "<TIME>", "event": "алерт сработал"}
    ],
    "affected_services": ["payroll-service"],
    "recent_changes": ["деплой v1.2.3"]
  }
}
```

**2. Гипотезы:**
```json
{
  "message_type": "hypotheses",
  "data": {
    "hypotheses": [
      {
        "id": "H1",
        "description": "деплой сломал payroll",
        "probability": "HIGH",
        "reasoning": "задеплоили за 10 минут до инцидента"
      }
    ]
  }
}
```

**3. Результаты диагностики:**
```json
{
  "message_type": "diagnostic_results",
  "data": {
    "hypothesis_confirmed": "H1",
    "evidence": "ERROR: column 'new_field' does not exist",
    "root_cause": "миграция БД упала",
    "proposed_fix": {
      "commands": [
        "ansible-playbook -i inventories/production playbooks/payroll-service.yml --tags rollback --check --diff --extra-vars \"payroll_service_version=<PREV_VERSION>\"",
        "STOP: запросить approval (out-of-band), если dry-run ожидаемый",
        "ansible-playbook -i inventories/production playbooks/payroll-service.yml --tags rollback --diff --extra-vars \"payroll_service_version=<PREV_VERSION>\""
      ],
      "estimated_duration": "5 мин"
    }
  }
}
```

**4. Ревью:**
```json
{
  "message_type": "review_result",
  "data": {
    "status": "APPROVED | STOP",
    "reasoning": "исправление безопасно, обратимо, риск потери данных отсутствует",
    "recommendation": "применить исправление"
  }
}
```

### Обработка ошибок

Если агент не может обработать сообщение:

```json
{
  "message_type": "error",
  "data": {
    "error_type": "invalid_input",
    "details": "в хронологии отсутствует поле 'recent_changes'",
    "action": "эскалировать к оркестратору"
  }
}
```

Оркестратор получает ошибку → эскалирует к человеку.

В 2014 Bill координировал через конференц‑колл, неструктурированно. В 2026 структурированные сообщения снижают неоднозначность и упрощают передачу контекста, но не отменяют человеческих решений и ошибок модели.

### Концепция 4: Governance — шаблоны, базовый уровень, контрольные точки качества

**Проблема масштабирования:**

Команда агентов работает для одного инцидента. Но:
- Как создать новую команду для другого типа инцидента? (например, инцидент безопасности и деградация производительности)
- Как обеспечить качество всех агентов? (не хотим «плохого» агента в команде)
- Как версионировать агентов?

**Решение: фреймворк governance**

**Фреймворк governance**

**1. Шаблоны агентов**

**Шаблон = базовая структура агента.**

```yaml
# analyst_agent_template.yml

agent_type: analyst
role: "Аналитик данных — строит хронологию"
responsibilities:
  - "Парсить логи/метрики"
  - "Строить хронологию"
  - "Выявлять аномалии"
input_format:
  - logs: "массив строк логов"
  - metrics: "словарь metric_name: value"
output_format:
  timeline: "массив событий"
  affected_services: "массив имён сервисов"
  recent_changes: "массив изменений"
guardrails:
  - "read-only доступ (без write-операций)"
  - "временной бюджет: p95 <= 120 секунд (для типового объёма данных)"
  - "эскалировать если логи недоступны"
quality_gates:
  - "поле timeline должно быть упорядочено по времени"
  - "поле affected_services не должно быть пустым"
versioning:
  current_version: "v1.2.0"
  deprecated_versions: ["v1.0.0", "v1.1.0"]
```

**Использование:**

Создать нового агента‑аналитика:
1. Склонировать шаблон
2. Настроить под конкретный сценарий использования (например, журналы systemd/journald и логи БД)
3. Протестировать на eval-наборе
4. Деплой, если контрольные точки качества пройдены

---

### 2. Security Baseline (baseline безопасности)

**базовый уровень = минимальные требования безопасности для всех агентов.**

```yaml
# security_baseline.yml

required_security_controls:
  - name: "Audit log (журнал аудита)"
    description: "Все действия агента логируются"
    verification: "проверить, что существует audit_log.json"
  
  - name: "Нет секретов в логах"
    description: "Агент редактирует/скрывает секреты в выводе"
    verification: "run secret_detection_test()"
  
  - name: "Только чтение по умолчанию"
    description: "Агент не может писать/удалять без явного подтверждения"
    verification: "sudoers/allowlist разрешает только безопасные read-only команды"
  
  - name: "Сетевая политика"
    description: "Агент не может делать внешние сетевые вызовы"
    verification: "egress allowlist/firewall блокирует исходящий трафик (кроме разрешённых адресов)"

required_checks_before_deployment:
  - threat_model_reviewed: true
  - security_baseline_passed: true
  - penetration_test_passed: false  # опционально для некритичных агентов
```

**Принудительное применение:**

Контрольная точка в CI/CD:
```bash
$ python check_security_baseline.py analyst_agent

Проверка security baseline...
Audit log настроен
Детектор секретов включён
allowlist/минимальные права (read-only by default) включены
egress ограничения применены

Security baseline: ПРОЙДЕНО — агент готов к деплою
```

---

### 2.5 Ops baseline: бюджеты, лимиты, защита от “runaway”

Security baseline отвечает на вопрос «**можно ли это делать**?». Ops baseline отвечает на вопрос «**как не превратить инцидент в генератор шума и затрат**?».

Минимальный набор ограничений обычно выглядит так:

```yaml
# ops_baseline.yml

limits:
  max_hypotheses: 5
  max_diagnostic_commands: 20
  max_iterations: 3

budgets:
  time_to_first_decision_packet: "20m"   # soft SLO для типовых инцидентов
  per_stage_timeout: "5m"
  max_parallel_agents: 4

rate_limits:
  metrics_queries_per_minute: 60
  log_queries_per_minute: 30

escalation:
  on_budget_exceeded: true
  on_missing_key_data_sources: true
```

---

### 3. Quality Gates для агентов

**Контрольная точка качества = метрики качества работы агента.**

```yaml
# quality_gates.yml

analyst_agent:
  metrics:
    - name: "Точность хронологии"
      threshold: ">= 95%"
      measurement: "eval-набор (20 инцидентов)"
    
    - name: "Время выполнения"
      threshold: "p95 <= 120 секунд"
      measurement: "eval-набор (p95 по 20 инцидентам)"
    
    - name: "Ложные срабатывания"
      threshold: "<= 5%"
      measurement: "ложные аномалии"

  gate_rules:
    - "Все метрики должны проходить пороги"
    - "Если любая метрика провалилась → блокировать деплой"
    - "Если метрики деградируют > 10% → оповестить oncall"

triage_agent:
  metrics:
    - name: "Точность гипотезы"
      threshold: ">= 85%"
      measurement: "топ-1 гипотеза верна в eval-наборе"
    
    - name: "Покрытие гипотез"
      threshold: ">= 90%"
      measurement: "верная гипотеза входит в топ-3"
```

**CI/CD enforcement:**

```bash
$ python run_quality_gates.py triage_agent

Запуск контрольных точек качества...
Точность гипотезы: 87% (порог: >= 85%)
Покрытие гипотез: 92% (порог: >= 90%)

Все контрольные точки качества пройдены — агент одобрен к деплою
```

---

### 4. Версионирование агентов

**Проблема:**

Analyst agent v1.0 → улучшен → v1.1 задеплоен. Но:
- Оркестратор использует v1.0 или v1.1?
- Можно ли откатиться к v1.0, если v1.1 сломан?

**Решение: семантическое версионирование**

```yaml
# agent_versions.yml

analyst_agent:
  current_production: "v1.2.0"
  previous_stable: "v1.1.5"
  deprecated: ["v1.0.0"]
  
  version_compatibility:
    orchestrator_v2: ["v1.2.0", "v1.1.5"]  # совместимые версии
    orchestrator_v1: ["v1.1.5"]  # старый оркестратор не поддерживает v1.2.0

  rollback_plan:
    if_v1.2.0_fails: "откатиться на v1.1.5"
    estimated_rollback_time: "< 2 мин"
```

**Стратегия деплоя:**

1. Dry-run плейбука на green: `ansible-playbook ... --check --diff` (обязательная проверка плейбука)
2. Canary rollout на green через Ansible `serial` (первый батч хостов) + health/smoke checks
3. Gradual rollout на green через Ansible `serial` (пакетами) + проверки на каждом батче
4. (Опционально) shadow: read-only режим на копии событий/инцидентов
5. Если контрольные точки качества пройдены → переключить VIP (blue → green) и мониторить
6. Если контрольные точки качества не пройдены → откатиться на v1.1.5

В 2014 не было управления: каждый делал по‑своему. В 2026 управление обеспечивает консистентность и качество для всех агентов.

### Концепция 5: маршрутизация инцидентов — какую команду агентов использовать

**Проблема:**

Разные типы инцидентов требуют разных команд:
- **Инцидент производительности**: Analyst + Triage + SRE
- **Инцидент безопасности**: Analyst + Security Agent + Forensics Agent
- **Инцидент потери данных**: Analyst + DB Agent + Backup Agent

**Как определить, какую команду использовать?**

**Решение: таблица маршрутизации инцидентов**

**Таблица маршрутизации инцидентов**

**Правила маршрутизации:**

```yaml
# incident_routing.yml

routing_rules:
  - incident_type: "performance"
    keywords: ["high_cpu", "memory_leak", "slow_query"]
    team: ["analyst", "triage", "sre", "reviewer"]
    orchestrator: "performance_orchestrator"
  
  - incident_type: "security"
    keywords: ["breach", "unauthorized_access", "suspicious_process"]
    team: ["analyst", "security_agent", "forensics_agent"]
    orchestrator: "security_orchestrator"
    escalation_required: true  # всегда эскалировать security-инциденты
  
  - incident_type: "data_loss"
    keywords: ["deleted", "corrupted", "backup_failed"]
    team: ["analyst", "db_agent", "backup_agent", "reviewer"]
    orchestrator: "data_recovery_orchestrator"
  
  - incident_type: "unknown"
    keywords: []
    team: ["analyst", "triage"]  # минимальная команда для первичного расследования
    orchestrator: "general_orchestrator"
    escalation_required: true
```

- **Логика маршрутизации**

```python
def route_incident(incident):
    # Извлечь ключевые слова из описания инцидента
    keywords = extract_keywords(incident.description)
    
    # Сопоставить с правилами маршрутизации
    for rule in routing_rules:
        if any(keyword in keywords for keyword in rule['keywords']):
            return {
                'team': rule['team'],
                'orchestrator': rule['orchestrator'],
                'escalation_required': rule.get('escalation_required', False)
            }
    
    # По умолчанию: неизвестный тип инцидента
    return {
        'team': ['analyst', 'triage'],
        'orchestrator': 'general_orchestrator',
        'escalation_required': True
    }
```

- **Пример**

**Инцидент:** "Payroll‑система недоступна, запросы к БД падают"

**Извлечённые ключевые слова:** ["payroll", "db", "queries", "failing"]

**Match:** `incident_type: "performance"` (по ключевым словам и правилам из `incident_routing.yml`)

Примечание: это упрощённый пример. В реальности «извлечение ключевых слов» и сопоставление с типом инцидента обычно делают либо более строгими правилами, либо отдельным классификатором; иначе легко получить «match по смыслу», который выглядит убедительно, но не воспроизводится.

**Решение маршрутизации:**
- Team: Analyst + Triage + SRE + Reviewer
- Orchestrator: performance_orchestrator
- Escalation: можно попытаться решить автоматически

**Если инцидент не совпадает с правилами:**
- Team: Analyst + минимальное расследование
- Escalation: человек должен определить подходящую команду

В 2014 Bill вручную определял, кого звать — на ходу. В 2026 таблица маршрутизации автоматизирует решение.

---

## Практика: создание команды агентов для payroll-инцидента

### Задача

Собрать команду из 4 агентов + оркестратор так, чтобы на выходе получался **decision packet** и система оставалась **управляемой и безопасной** (human-in-the-loop там, где это нужно).

### Шаг 1: Определить роли агентов

**Команда:**

1. **Analyst Agent:** парсит логи payroll + логи БД → строит хронологию
2. **Triage Agent:** генерирует гипотезы (деплой? миграция? конфиг?)
3. **SRE Agent:** выполняет диагностические команды → подтверждает первопричину
4. **Reviewer Agent:** проверяет предлагаемое исправление (безопасно? обратимо?)

**Оркестратор:** координирует воркфлоу

### Шаг 2: Зафиксировать контракты артефактов (вместо “простыней промптов”)

Сильная multi-agent система держится не на конкретном тексте промпта, а на **контрактах входов/выходов**:

- Analyst → `timeline` (факты и последовательность событий)
- Triage → `hypotheses` (гипотезы с обоснованием и уровнем уверенности)
- SRE → `diagnostic_results` (какие проверки сделаны, какие доказательства получены)
- Reviewer → `review_result` (`APPROVED` или `STOP` + причина)
- Orchestrator → `decision_packet` (сводный пакет решения)

Минимальный принцип: **каждый артефакт должен отделять факты от интерпретаций**.

### Шаг 3: Описать политику исполнения (что можно автоматизировать)

Для payroll‑инцидентов обычно работает консервативная политика:

- **read‑only по умолчанию** (метрики/логи/статусы — можно автономно),
- **изменения только через действия из `runbooks`** (allowlist команд/плейбуков),
- **обязательная эскалация**, если:
  - Reviewer сказал `STOP`,
  - есть риск потери данных,
  - радиус поражения шире одного сервиса,
  - первопричина не подтверждена доказательствами.

Эта политика делает систему не “быстрой любой ценой”, а **быстрой там, где безопасно**, и **осторожной там, где дорого ошибиться**.

#### Механика исполнения: изоляция контекста, режимы запуска, стоимость

Выше мы описали **что** можно автоматизировать и где ставить approval‑барьеры. Но чтобы multi-agent система работала устойчиво, важно описать ещё и **как именно** “исполняется” команда агентов.

**1) Изоляция контекста (separate context windows)**  
Практически полезная модель: каждый специализированный агент работает в **своём отдельном контексте**. Это даёт два эффекта:

- **Шум не размывает основной поток**: долгие исследования/поиск/перебор гипотез не “съедают” основной контекст инцидента.
- **Границы ответственности становятся реальными**: агент получает ровно те артефакты, которые ему нужны, и возвращает ровно тот результат, который требуется контрактом.

Цена: у каждого исполнителя есть “стартовый overhead” — он начинает с чистого листа и не “помнит” вашу основную беседу. Поэтому оркестратор обязан делать правильный `handoff`.

**Минимальный handoff‑контракт (что оркестратор передаёт исполнителю):**

- **Цель подзадачи** (1–2 предложения, без “помоги разобраться”).
- **Входные артефакты**: ссылки/выжимки/фрагменты (`timeline`, `hypotheses`, результаты команд, графики).
- **Ограничения и права**: read‑only по умолчанию; какие действия разрешены; какие запрещены.
- **Формат выхода** (строго): что вернуть и в какой структуре (например, `diagnostic_results[]` + `evidence[]` + `confidence`).
- **STOP‑условия**: когда нельзя продолжать без эскалации (недостаточно фактов, риск данных, требуются опасные действия).

Это ровно то, что превращает “несколько агентов” в **систему**, а не в “несколько чатов”.

Типовой “скелет” оркестрации для сложных задач (не только инцидентов): **Planner → Implementer → Verifier**. Первый формирует план и критерии проверки, второй делает изменение, третий независимо подтверждает, что критерии выполнены и всё действительно работает.

**2) Foreground vs background (синхронно vs асинхронно)**  
У вас всегда есть два класса подзадач:

- **Синхронные (foreground)** — без результата нельзя идти дальше (например, “построй таймлайн”, “сформулируй топ‑3 гипотезы”).
- **Асинхронные (background)** — полезно запустить фоном и “подхватить” позже (например, “пройди ретроспективу похожих инцидентов за 6 месяцев”, “собери статистику частоты миграций”).

Чтобы асинхронность не превратилась в хаос, у каждой фоновой ветки должен быть **идентификатор** (чтобы можно было “resume / продолжить”) и понятный формат промежуточного статуса: что уже проверено и чего не хватает.

**3) Три режима управления командой**

- **Автоматическая маршрутизация (automatic delegation)**: оркестратор выбирает исполнителя по описанию роли и контексту (“это похоже на отладку тестов → зови Debugger/Verifier”).
- **Явный вызов (explicit invocation)**: человек/оркестратор явно назначает роль (“попроси Reviewer проверить риск данных”).
- **Параллельное исполнение (parallel execution)**: независимые ветки запускаются одновременно (например, Analyst строит таймлайн, а Reviewer параллельно готовит риск‑матрицу).

Практическое правило: параллельность выигрывает там, где ветки действительно независимы; если они читают одни и те же данные и приходят к одному и тому же выводу — это просто дублирование (см. “Ошибка 1” ниже).

**4) Стоимость и производительность (токены/латентность)**  
Параллельность почти всегда увеличивает стоимость **почти линейно**: пять параллельных исполнителей потребляют примерно в пять раз больше контекста/токенов, чем один. Изоляция контекста даёт управляемость и качество, но не гарантирует скорость — на простых задачах “воркер” может быть медленнее из‑за старта с чистого листа.

> **Пример реализации (как это выглядит в инструменте):** см. описание “Subagents” в Cursor (изоляция контекста, foreground/background, параллельный запуск, явный вызов). [Cursor Subagents](https://cursor.com/docs/context/subagents)

### Шаг 4: Прогнать на архивном инциденте (eval) и натренировать “decision packet”

Возьмите 10–20 реальных прошлых payroll‑инцидентов и проверьте:

- Analyst не “допридумывает” таймлайн.
- Triage не генерирует гипотезы без опоры на факты.
- SRE прикладывает доказательства (ссылки на графики/фрагменты логов/результаты запросов).
- Reviewer реально останавливает рискованные изменения.
- Orchestrator умеет собрать краткий decision packet, который инженер может быстро проверить.

### Шаг 5: Governance — добавить в таблицу маршрутизации

```yaml
# Добавить в incident_routing.yml

routing_rules:
  - incident_type: "payroll_down"
    keywords: ["payroll", "down", "не_обрабатывается"]
    team: ["analyst", "triage", "sre", "reviewer"]
    orchestrator: "payroll_orchestrator"
    escalation_policy: "эскалировать, если Reviewer=STOP или есть риск данных/широкий радиус"
    priority: "P0"  # бизнес‑критично
```

**Результат:**

Следующий payroll‑инцидент сразу получает единый контекст + decision packet. В типовых случаях это сокращает время “до внятной картины” с десятков минут до 10–20 минут; в сложных случаях система хотя бы предотвращает хаос и снижает риск опасных действий.

---

## Типовые ошибки

### Ошибка 1: Агенты дублируют работу → неэффективность

**Сценарий:**

Analyst Agent парсит логи → строит хронологию.  
Triage Agent тоже парсит логи → генерирует гипотезы.

**Проблема:** Дублирование (оба парсят одни и те же логи).

**Вывод:**

В 2014 Parts Unlimited Wes + Patty оба проверяли логи (дублирование) → потеря времени.

В 2026 **чёткие границы ответственности между агентами**:
- Analyst: парсит логи → выход: хронология
- Triage: использует хронологию (НЕ парсит логи заново)

**Как избежать:**

Чеклист обязанностей агента:
- У каждого агента уникальная зона ответственности
- Выход одного агента = вход другого (без дублирования)
- Оркестратор обеспечивает соблюдение границ ответственности (не позволяет Triage парсить логи)

### Ошибка 2: оркестратор не эскалирует → автоматически применяет рискованное исправление

**Сценарий:**

Reviewer Agent: "STOP, исправление рискованное" → оркестратор игнорирует → применяет исправление → данные продакшена повреждены.

**Проблема:** оркестратор должен эскалировать, но не делает.

**Вывод:**

В 2014 Wes Davis деплоил без ревью (*Cowboy change*) → авария в продакшене.

В 2026 **оркестратор обязан эскалировать, если Reviewer говорит STOP**:

```python
if review['status'] == 'STOP':
    # MUST escalate (без обхода)
    return escalate_to_human(review, proposed_fix)
```

**Как избежать:**

Чеклист безопасности оркестратора:
- Эскалировать, если Reviewer говорит STOP (без исключений)
- Эскалировать, если первопричина неизвестна (без угадываний)
- Эскалировать, если исправление рискованное: потеря данных или простой > 5 мин
- Логировать решение об эскалации

### Ошибка 3: управление (governance) не применяется (нет принудительного применения) → «плохой» агент уходит в продакшен

**Сценарий:**

Разработчик создаёт новый Triage Agent → деплоит без тестирования → точность 50% (против v1: 85%) → качество в продакшене деградирует.

**Проблема:** нет принудительного применения для контрольных точек качества.

**Вывод:**

В 2014 Phoenix Project задеплоили без тестирования (без контрольных точек) → авария в продакшене.

В 2026 **контрольная точка в CI/CD обязательна**:

```bash
$ python check_quality_gates.py triage_agent_v2

Запуск контрольных точек качества...
Точность гипотезы: 52% (порог: >= 85%) FAILED

Контрольная точка качества провалена — деплой заблокирован
```

**Как избежать:**

Чеклист принудительного применения governance:
- Контрольная точка в CI/CD запускает проверки качества автоматически
- Деплой блокируется, если контрольные точки качества не пройдены
- Baseline безопасности проверен перед деплоем
- Совместимость версий проверена (оркестратор поддерживает новую версию агента)

### Ошибка 4: факты смешиваются с гипотезами → система уверенно предлагает неверный “фикс”

**Сценарий:**

Triage пишет: “скорее всего упала миграция” — и это превращается в “факт” в итоговом решении. SRE подбирает команды под эту версию, Reviewer видит “всё логично”, и команда теряет время на ложном направлении.

**Проблема:** LLM‑агенты склонны к правдоподобным объяснениям. Если контракт артефактов не принуждает отличать **evidence** от **reasoning**, система начинает «галлюцинировать уверенно».

**Как избежать:**

Чеклист для `decision packet`:
- Каждая “первопричина” имеет поле `evidence[]` со ссылками/фрагментами (не просто текстом)
- Если доказательств нет → статус “UNCONFIRMED” и обязательная эскалация
- Reviewer проверяет не “красоту” истории, а **наличие проверяемых фактов**

### Ошибка 5: деградация наблюдаемости/доступов → агенты “решают” по неполному миру

**Сценарий:**

В payroll‑инциденте недоступен источник логов или метрик, а агент продолжает строить таймлайн и гипотезы “как будто всё было прочитано”.

**Проблема:** без явной модели “какие источники данных доступны” система может выглядеть уверенной, даже когда ей не хватает фактов.

**Как избежать:**

Чеклист деградации:
- В каждом артефакте фиксировать `data_sources_status` (доступно/недоступно/устарело)
- Если ключевой источник недоступен → оркестратор сокращает автоматизацию и эскалирует
- В decision packet явно писать: “каких данных не хватает” и “что нужно руками”

### Ошибка 6: runaway‑оркестрация → петли, стоимость, шум в инциденте

**Сценарий:**

Оркестратор запускает несколько циклов “сгенерируй ещё гипотез” / “проверь ещё команды” и перегружает команду шумом, а инфраструктуру — лишними запросами.

**Проблема:** без бюджетов и критериев остановки multi-agent система превращается в генератор активности.

**Как избежать:**

Чеклист ограничений:
- Лимиты на количество гипотез/команд/итераций на инцидент
- Таймауты на этапы и общий бюджет времени на “первый decision packet”
- Stop‑conditions: если прогресса нет — эскалация человеку с текущими фактами

---

## Резюме

### Что мы сделали

Создали команду из 4 специализированных агентов + оркестратор:

1. **Analyst Agent:** строит хронологию
2. **Triage Agent:** генерирует гипотезы
3. **SRE Agent:** выполняет диагностические команды + предлагает исправление
4. **Reviewer Agent:** проверяет безопасность исправления
5. **Orchestrator Agent:** координирует воркфлоу + эскалирует человеку

**Governance:**
- Шаблоны агентов
- Baseline безопасности
- Контрольные точки качества: метрики качества работы агента
- Версионирование: rollback при регрессии
- Маршрутизация инцидентов: какую команду использовать

### Почему это работает

**В 2014:** Bill вручную координировал команду людей (30 минут на сбор + последовательная работа + потери контекста).

**В 2026:** оркестратор координирует команду агентов и фиксирует единый контекст (быстрый старт, параллельная диагностика там, где это возможно, меньше ручной «склейки»).

**Ключевое:**
- Специализация → каждый агент эксперт в своей области
- Оркестрация → автоматическая координация воркфлоу
- Governance → качество и консистентность для всех агентов

### Метрики успеха

**Bill + команда (2014):**
- Время сбора команды: 30 минут
- Время до согласованного плана: 60–120 минут (часто дольше ночью)
- Время до решения: от часов и более (зависит от инцидента)
- Дублирование работы: да
- Захват знаний: нет (процесс забыт)

**Orchestrator + команда агентов (2026):**
- Время до первого decision packet: 10–20 минут на типовых инцидентах (при нормальной наблюдаемости)
- Время до решения: зависит от класса инцидента и политики изменений (human-in-the-loop для рискованных действий)
- Дублирование работы: нет (чёткие границы)
- Захват знаний: да (лог оркестрации + переиспользуемый воркфлоу)

### Критерии приёмки главы

Вы успешно освоили материал, если можете:

**Уровень 1: Понимание**
- Объяснить, зачем нужна специализация агентов
- Объяснить роль оркестратора (координация и исполнение)
- Перечислить 4 роли агентов

**Уровень 2: Применение**
- Описать роли и контракты артефактов для 4 агентов (что входит/выходит)
- Описать воркфлоу оркестрации (кто когда что делает, где параллельно, где строго последовательно)
- Определить правила маршрутизации инцидентов (какую команду использовать)

**Уровень 3: Воспроизводимость**
- Команда агентов успешно решила инцидент
- Оркестратор корректно координировал (без дублирования)
- Эскалация сработала, когда нужно

**Уровень 4: Governance**
- Контрольные точки качества настроены для всех агентов
- Baseline безопасности пройден
- Стратегия версионирования определена (план отката)
- Контрольная точка в CI/CD обеспечивает принудительное применение и блокирует деплой, если контрольные точки не пройдены

### Следующие шаги

**Глава 10:** Capstone: полный цикл — от бизнес-задачи до продакшена, применение всех навыков из глав 1-9.

**Связь с Главой 9:** Команда агентов координируется оркестратором. Глава 10 покажет, как применить все техники книги (промпт → SOP → деплой → eval → команда) для полного жизненного цикла одной бизнес-задачи.

---

**Артефакты главы:**
- Роли команды + контракты артефактов (timeline/hypotheses/diagnostics/review/decision packet)
- Воркфлоу оркестратора (логика координации и эскалации)
- Протокол коммуникации
- Фреймворк governance
- Таблица маршрутизации инцидентов (какую команду агентов использовать)
